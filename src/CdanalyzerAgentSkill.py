import json
import asyncio
import os
import fnmatch
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Tuple
from collections import defaultdict
import re
import httpx
import asyncio
from dotenv import load_dotenv

load_dotenv()

class CdanalyzerAgentSkill:
    def __init__(self):
        """
        åˆå§‹åŒ–ä»£ç è´¨é‡åˆ†æå·¥å…·
        """
        self.name = "CdanalyzerAgentSkill"
        self.version = "1.0.0"
        self.default_standards = {
            "python": "pylint",
            "javascript": "eslint",
            "java": "checkstyle",
            "cpp": "cppcheck",
            "csharp": "roslyn-analyzers",
            "go": "golangci-lint",
            "typescript": "typescript-eslint"
        }
        self.risk_levels = {
            "critical": {"weight": 4, "color": "#ff0000", "label": "è‡´å‘½"},      # çº¢è‰²
            "high": {"weight": 3, "color": "#ff9500", "label": "é«˜çº§"},         # æ·±æ©™çº¢è‰²ï¼Œä¸ä¸­çº§é»„è‰²æ›´å¥½åŒºåˆ†
            "medium": {"weight": 2, "color": "#ffff66", "label": "ä¸­çº§"},       # æµ…é»„ç»¿è‰²ï¼Œä¸é«˜çº§é¢œè‰²å½¢æˆå¯¹æ¯”
            "low": {"weight": 1, "color": "#ccffcc", "label": "æ™®é€š"}           # æµ…ç»¿è‰²
        }
        # å¤§æ¨¡å‹APIé…ç½®
        self.llm_configs = {}
        # æ§åˆ¶æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹çš„é…ç½®é¡¹ï¼Œé»˜è®¤ä¸º0ï¼ˆå³è®¿é—®å¤§æ¨¡å‹ï¼‰
        self.use_llm_config = 0

    def show_llm_configs(self):
        """
        æ˜¾ç¤ºå½“å‰å¤§æ¨¡å‹é…ç½®ä¿¡æ¯
        """
        print(f"=== å¤§æ¨¡å‹é…ç½®çŠ¶æ€ ===")
        print(f"å½“å‰é…ç½®çš„å¤§æ¨¡å‹æ•°é‡: {len(self.llm_configs)}")
        if self.llm_configs:
            for provider, config in self.llm_configs.items():
                print(f"æä¾›å•†: {provider}")
                print(f"æ¨¡å‹: {config['model']}")
                print(f"API Base URL: {config['base_url']}")
                print(f"Top_p: {config['top_p']}")
                print(f"API Key: {'*' * 20}{config['api_key'][-4:] if config['api_key'] and len(config['api_key']) >= 4 else ''}")
                print(f"---------------------")
        else:
            print("çŠ¶æ€: æœªé…ç½®ä»»ä½•å¤§æ¨¡å‹")
        print(f"=====================")

    def set_llm_config(self, provider: str, api_key: str = None, base_url: str = None, model: str = None, top_p: float = 0.7):
        """
        è®¾ç½®å¤§æ¨¡å‹APIé…ç½®
        """
        import os

        if not provider:
            raise ValueError("LLMæä¾›å•†ä¸èƒ½ä¸ºç©º")
        
        # ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™å¤„ç†
        provider_lower = provider.lower()

        # å¦‚æœæ²¡æœ‰æä¾›api_keyï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not api_key:
            env_key = f'{provider_lower.upper()}_API_KEY'
            api_key = os.getenv(env_key, '')

        # å¯¹äºéœ€è¦API Keyçš„æä¾›å•†è¿›è¡Œæ£€æŸ¥
        if provider_lower not in ['ollama'] and not api_key:
            print(f"âš  è­¦å‘Šï¼š{provider}éœ€è¦API Keyï¼Œä½†æœªæä¾›")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œåªæ˜¯è·³è¿‡é…ç½®
            return

        # å¦‚æœæ²¡æœ‰æä¾›base_urlï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not base_url:
            env_url = f'{provider_lower.upper()}_BASE_URL'
            base_url = os.getenv(env_url) or os.getenv('LLM_BASE_URL')
        
        # å¦‚æœæ²¡æœ‰æä¾›modelï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not model:
            env_model = f'{provider_lower.upper()}_MODEL'
            model = os.getenv(env_model) or os.getenv('LLM_MODEL')

        # è®¾ç½®é»˜è®¤å€¼
        base_url = base_url or "https://api.openai.com/v1"
        model = model or "gpt-3.5-turbo"
        
        self.llm_configs[provider_lower] = {
            "api_key": api_key,
            "base_url": base_url,
            "model": model,
            "top_p": top_p
        }

        # æ‰“å°å¤§æ¨¡å‹è¿æ¥ä¿¡æ¯
        print(f"=== å¤§æ¨¡å‹è¿æ¥ä¿¡æ¯ ===")
        print(f"æä¾›å•†: {provider}")
        print(f"æ¨¡å‹: {model}")
        print(f"API Base URL: {base_url}")
        print(f"Top_p: {top_p}")
        print(f"API Key: {'*' * 20}{api_key[-4:] if api_key and len(api_key) >= 4 else ''}")  # éšè—å¤§éƒ¨åˆ†APIå¯†é’¥
        print(f"=====================")

    async def _call_llm_api(self, provider: str, prompt: str) -> str:
        """
        è°ƒç”¨å¤§æ¨¡å‹APIè·å–å»ºè®®
        """
        # ä½¿ç”¨å°å†™providerä½œä¸ºé”®å
        provider_lower = provider.lower()
        if provider_lower not in self.llm_configs:
            return "æœªé…ç½®å¤§æ¨¡å‹API"

        config = self.llm_configs[provider]
        headers = {
            "Authorization": f"Bearer {config['api_key']}",
            "Content-Type": "application/json"
        }

        # æ ¹æ®ä¸åŒçš„æä¾›å•†æ„å»ºpayloadå’Œç¡®å®šAPIç«¯ç‚¹
        if provider.lower() in ['qwen', 'é€šä¹‰åƒé—®', 'aliyun', 'dashscope']:
            # é˜¿é‡Œäº‘é€šä¹‰åƒé—®APIå…¼å®¹æ¨¡å¼
            payload = {
                "model": config['model'],
                "messages": [{"role": "user", "content": prompt}],
                "top_p": config.get('top_p', 0.8)
            }
            api_endpoint = f"{config['base_url']}/chat/completions"
        elif provider.lower() in ['zhipu', 'æ™ºè°±AI']:
            # æ™ºè°±AI API
            payload = {
                "model": config['model'],
                "messages": [{"role": "user", "content": prompt}],
                "top_p": config.get('top_p', 0.7)
            }
            api_endpoint = f"{config['base_url']}/chat/completions"
        elif provider.lower() in ['ollama']:
            # Ollama API
            payload = {
                "model": config['model'],
                "prompt": prompt,
                "stream": False
            }
            # Ollamaä½¿ç”¨ä¸åŒçš„APIç«¯ç‚¹
            api_endpoint = f"{config['base_url']}/api/generate"
            # Ollamaä¸éœ€è¦Authorizationå¤´éƒ¨
            headers = {"Content-Type": "application/json"}
        else:
            # é»˜è®¤ä¸ºOpenAIæ ¼å¼
            payload = {
                "model": config['model'],
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7
            }
            api_endpoint = f"{config['base_url']}/chat/completions"

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    api_endpoint,
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                result = response.json()
                
                # æ ¹æ®ä¸åŒæä¾›å•†è§£æå“åº”
                if provider.lower() in ['ollama']:
                    # Ollamaå“åº”æ ¼å¼ä¸åŒ
                    return result.get("response", "æ— æ³•è§£æOllamaå“åº”")
                else:
                    # å…¶ä»–æä¾›å•†ä½¿ç”¨æ ‡å‡†æ ¼å¼
                    return result["choices"][0]["message"]["content"].strip()
        except Exception as e:
            print(f"è°ƒç”¨å¤§æ¨¡å‹APIå¤±è´¥: {str(e)}")
            return f"è·å–AIå»ºè®®å¤±è´¥: {str(e)}"

    async def _get_ai_suggestions(self, issues: List[Dict[str, Any]]) -> List[str]:
        """
        ä¸ºæ¯ä¸ªé—®é¢˜è·å–AIå»ºè®®
        """
        # å¦‚æœuse_llm_configä¸º1ï¼Œåˆ™ç›´æ¥è¿”å›"æ— "
        if self.use_llm_config == 1:
            return ["æ— " for _ in issues]

        suggestions = []

        # æ ¹æ®é…ç½®é€‰æ‹©åˆé€‚çš„LLMæä¾›å•†ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªé…ç½®çš„æä¾›å•†ï¼‰
        if self.llm_configs:
            provider = next(iter(self.llm_configs.keys()))
            print(f"ä½¿ç”¨å¤§æ¨¡å‹æä¾›å•†: {provider}")
            
            tasks = []
            for issue in issues:
                prompt = (
                    f"åˆ†æä»¥ä¸‹ä»£ç é—®é¢˜å¹¶æä¾›ä¿®æ­£å»ºè®®ï¼š\n"
                    f"é—®é¢˜ç±»å‹ï¼š{issue['type']}\n"
                    f"ä¸¥é‡ç¨‹åº¦ï¼š{issue['severity']}\n"
                    f"é—®é¢˜æè¿°ï¼š{issue['message']}\n"
                    f"è§£å†³æ–¹æ¡ˆï¼š{issue['solution']}\n"
                    f"è¯·æä¾›ä¸€ä¸ªç®€æ´çš„çƒ­é—¨åŸå› è§£é‡Šå’Œä¿®æ­£æ–¹æ¡ˆã€‚"
                )
                task = self._call_llm_api(provider, prompt)
                tasks.append(task)

            suggestions = await asyncio.gather(*tasks)
            return suggestions
        else:
            return ["æœªé…ç½®å¤§æ¨¡å‹API" for _ in issues]

    async def _estimate_development_cost(self, total_files: int, total_lines: int) -> float:
        """
        ä¼°ç®—å¼€å‘æˆæœ¬ï¼ˆäºº/æ—¥ï¼‰
        """
        if self.use_llm_config == 1:
            return 0.00  # å¦‚æœä¸ä½¿ç”¨å¤§æ¨¡å‹ï¼Œåˆ™è¿”å›0
        
        if not self.llm_configs:
            print("æœªé…ç½®å¤§æ¨¡å‹ï¼Œæ— æ³•ä¼°ç®—å¼€å‘æˆæœ¬")
            return 0.00
        
        # æ„å»ºä¼°ç®—æç¤º
        prompt = (
            f"æ ¹æ®ä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ä¼°ç®—å…¶åœ¨2020å¹´ä¹‹å‰ä¼ ç»Ÿæ‰‹å·¥å¼€å‘æ¨¡å¼ä¸‹çš„å¼€å‘æˆæœ¬ï¼š\n"
            f"æ–‡ä»¶æ•°é‡ï¼š{total_files}\n"
            f"ä»£ç è¡Œæ•°ï¼š{total_lines}\n"
            f"è¯·åŸºäº2020å¹´ä¹‹å‰æ²¡æœ‰AIè¾…åŠ©å·¥å…·çš„å¼€å‘æ•ˆç‡ï¼Œè€ƒè™‘ç¼–ç ã€è°ƒè¯•ã€æµ‹è¯•ç­‰å› ç´ ï¼Œ"
            f"ä¼°ç®—è¯¥é¡¹ç›®æ‰€éœ€çš„äººåŠ›å¼€å‘æ—¶é—´ï¼ˆå•ä½ï¼šäºº/æ—¥ï¼‰ï¼Œç»“æœç²¾ç¡®åˆ°å°æ•°ç‚¹åä¸¤ä½ï¼Œ"
            f"å¦‚æœä¼°ç®—ç»“æœå¤§äº10ï¼Œåˆ™å¾ˆæœ‰å¯èƒ½ä¼°ç®—é”™è¯¯ï¼Œè¯·é‡æ–°ä¼°ç®—ã€‚"
        )
        
        # è·å–ä¼°ç®—ç»“æœ
        try:
            provider = next(iter(self.llm_configs.keys()))
            result = await self._call_llm_api(provider, prompt)
            
            # ä»ç»“æœä¸­æå–æ•°å­—
            import re
            numbers = re.findall(r'\d+\.?\d*', result)
            if numbers:
                return round(float(numbers[0]), 2)
            else:
                # å¦‚æœAIæ²¡æœ‰è¿”å›æ•°å­—ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤å€¼
                return round((total_lines / 100) + (total_files * 0.5), 2)  # ä¼°ç®—å…¬å¼ï¼šæ¯100è¡Œä»£ç éœ€è¦1äººæ—¥ï¼Œæ¯ä¸ªæ–‡ä»¶éœ€è¦0.5äººæ—¥
        except Exception as e:
            print(f"ä¼°ç®—å¼€å‘æˆæœ¬æ—¶å‡ºé”™: {e}")
            # å‡ºé”™æ—¶ä½¿ç”¨é»˜è®¤ä¼°ç®—å…¬å¼
            return round((total_lines / 100) + (total_files * 0.5), 2)

    async def _get_maintenance_recommendation(self, total_files: int, total_lines: int, 
                                       language_breakdown: dict, cost_estimate: float) -> dict:
        """
        è·å–ç»´æŠ¤å»ºè®®
        """
        if self.use_llm_config == 1:
            return {
                "worth_maintaining": "å¦",
                "reasoning": "ç”±äºæœªå¯ç”¨å¤§æ¨¡å‹ï¼Œæ— æ³•è¿›è¡Œæ™ºèƒ½åˆ†æï¼Œä¿å®ˆèµ·è§å»ºè®®ä¸ç»§ç»­ç»´æŠ¤ã€‚"
            }
        
        if not self.llm_configs:
            print("æœªé…ç½®å¤§æ¨¡å‹ï¼Œæ— æ³•æä¾›ç»´æŠ¤å»ºè®®")
            return {
                "worth_maintaining": "å¦",
                "reasoning": "ç”±äºæœªé…ç½®å¤§æ¨¡å‹ï¼Œæ— æ³•è¿›è¡Œæ™ºèƒ½åˆ†æï¼Œä¿å®ˆèµ·è§å»ºè®®ä¸ç»§ç»­ç»´æŠ¤ã€‚"
            }
        
        # æ„å»ºç»´æŠ¤å»ºè®®æç¤º
        tech_stack = ", ".join(language_breakdown.keys())
        prompt = (
            f"æ ¹æ®ä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ï¼Œåˆ†æè¯¥é¡¹ç›®æ˜¯å¦å€¼å¾—ç»§ç»­ç»´æŠ¤ï¼š\n"
            f"æ–‡ä»¶æ•°é‡ï¼š{total_files}\n"
            f"ä»£ç è¡Œæ•°ï¼š{total_lines}\n"
            f"æŠ€æœ¯æ ˆï¼š{tech_stack}\n"
            f"ä¼°ç®—å¼€å‘æˆæœ¬ï¼ˆäºº/æ—¥ï¼‰ï¼š{cost_estimate}\n"
            f"è¯·åˆ†ææ­¤é¡¹ç›®æ˜¯å¦å€¼å¾—ç»§ç»­ç»´æŠ¤ï¼Œåªå›ç­”'æ˜¯'æˆ–'å¦'ï¼Œå¹¶æä¾›ä¸è¶…è¿‡500å­—çš„ç†ç”±è¯´æ˜ã€‚"
            f"è¿”å›æ ¼å¼ï¼š\n"
            f"{{\n"
            f'  "worth_maintaining": "æ˜¯" æˆ– "å¦",\n'
            f'  "reasoning": "ç†ç”±è¯´æ˜"\n'
            f"}}"
        )
        
        try:
            provider = next(iter(self.llm_configs.keys()))
            result = await self._call_llm_api(provider, prompt)
            
            # å°è¯•è§£æè¿”å›çš„JSON
            import json
            try:
                parsed_result = json.loads(result)
                return {
                    "worth_maintaining": parsed_result.get("worth_maintaining", "å¦"),
                    "reasoning": parsed_result.get("reasoning", "æ— æ³•è§£æAIè¿”å›çš„å»ºè®®")
                }
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                lines = result.split('\n')
                worth_maintaining = "å¦"  # é»˜è®¤å€¼
                reasoning = "æœªèƒ½ä»AIå“åº”ä¸­æå–åˆ°æ˜ç¡®çš„ç»´æŠ¤å»ºè®®"
                
                for line in lines:
                    if "ã€æ­¤é¡¹ç›®æ˜¯å¦å€¼å¾—ç»§ç»­ç»´æŠ¤ã€‘" in line or "worth_maintaining" in line:
                        if "æ˜¯" in line:
                            worth_maintaining = "æ˜¯"
                        elif "å¦" in line:
                            worth_maintaining = "å¦"
                    elif "ã€åŸå› è¯´æ˜ã€‘" in line or "reasoning" in line:
                        reasoning = line.replace("ã€åŸå› ç”Ÿæ˜ã€‘:", "").replace("reasoning:", "").strip()
                
                return {
                    "worth_maintaining": worth_maintaining,
                    "reasoning": reasoning
                }
        except Exception as e:
            print(f"è·å–ç»´æŠ¤å»ºè®®æ—¶å‡ºé”™: {e}")
            return {
                "worth_maintaining": "å¦",
                "reasoning": f"è·å–AIå»ºè®®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            }

    async def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»£ç è´¨é‡åˆ†æçš„ä¸»è¦æ–¹æ³•
        
        Args:
            inputs: è¾“å…¥å‚æ•°å­—å…¸
            
        Returns:
            åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
        """
        try:
            target_path = inputs.get("target_path", "")
            language_types = inputs.get("language_types", [])
            analysis_standard = inputs.get("analysis_standard", {})
            exclude_patterns = inputs.get("exclude_patterns", [".svn", ".git", "__pycache__", "*.gitignore"])
            report_format = inputs.get("report_format", ["html", "pdf", "txt"])
            report_path = inputs.get("report_path", "./reports")
            ui_mode = inputs.get("ui_mode", False)

            # è·å–å¤§æ¨¡å‹é…ç½®å‚æ•°
            llm_provider = inputs.get("llm_provider")
            llm_api_key = inputs.get("llm_api_key")
            llm_base_url = inputs.get("llm_base_url")
            llm_model = inputs.get("llm_model")
            llm_top_p = inputs.get("llm_top_p", 0.7)  # é»˜è®¤top_på€¼
            
            # è·å–æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹çš„é…ç½®é¡¹
            use_llm = inputs.get("use_llm_config")
            if use_llm is not None:
                self.use_llm_config = int(use_llm)
            
            # å¦‚æœæ²¡æœ‰é€šè¿‡å‚æ•°æä¾›é…ç½®ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
            import os
            if not llm_provider:
                llm_provider = os.getenv('LLM_PROVIDER') or os.getenv('DEFAULT_LLM_PROVIDER')
            if not llm_api_key:
                # æ ¹æ®æä¾›å•†ä»å¯¹åº”ç¯å¢ƒå˜é‡è·å–
                env_key = f'{llm_provider.upper()}_API_KEY' if llm_provider else 'OPENAI_API_KEY'
                llm_api_key = os.getenv(env_key) or os.getenv('LLM_API_KEY')
            if not llm_base_url:
                env_url = f'{llm_provider.upper()}_BASE_URL' if llm_provider else 'OPENAI_BASE_URL'
                llm_base_url = os.getenv(env_url) or os.getenv('LLM_BASE_URL')
            if not llm_model:
                env_model = f'{llm_provider.upper()}_MODEL' if llm_provider else 'OPENAI_MODEL'
                llm_model = os.getenv(env_model) or os.getenv('LLM_MODEL')

            # å¦‚æœæä¾›äº†å¤§æ¨¡å‹é…ç½®ï¼Œåˆ™è®¾ç½®
            # ç‰¹åˆ«å¤„ç†Ollamaè¿™ç±»ä¸éœ€è¦API Keyçš„æä¾›å•†
            if llm_provider and self.use_llm_config == 0:  # åªæœ‰å½“use_llm_configä¸º0æ—¶æ‰è®¾ç½®å¤§æ¨¡å‹é…ç½®
                if llm_provider.lower() == 'ollama':
                    # Ollamaé€šå¸¸ä¸éœ€è¦API Keyï¼Œæ‰€ä»¥å³ä½¿æ²¡æœ‰api_keyä¹Ÿå¯ä»¥è®¾ç½®
                    self.set_llm_config(llm_provider, llm_api_key or '', llm_base_url, llm_model, llm_top_p)
                    print(f"âœ“ å·²é…ç½®Ollamaå¤§æ¨¡å‹")
                else:
                    if llm_api_key:
                        # å¯¹äºå…¶ä»–æä¾›å•†ï¼Œéœ€è¦API Key
                        self.set_llm_config(llm_provider, llm_api_key, llm_base_url, llm_model, llm_top_p)
                        print(f"âœ“ å·²é…ç½®{llm_provider}å¤§æ¨¡å‹")
                    else:
                        print(f"âš  è­¦å‘Šï¼š{llm_provider}éœ€è¦API Keyï¼Œä½†æœªæä¾›ï¼Œè·³è¿‡é…ç½®")

                # æ‰“å°å¤§æ¨¡å‹è¿æ¥ä¿¡æ¯
                if llm_provider in self.llm_configs:
                    print(f"=== å¤§æ¨¡å‹è¿æ¥ä¿¡æ¯ ===")
                    print(f"æä¾›å•†: {llm_provider}")
                    print(f"æ¨¡å‹: {llm_model or 'default'}")
                    print(f"API Base URL: {llm_base_url or 'default'}")
                    print(f"Top_p: {llm_top_p}")
                    print(f"API Key: {'*' * 20}{llm_api_key[-4:] if llm_api_key and len(llm_api_key) >= 4 else ''}")  # éšè—å¤§éƒ¨åˆ†APIå¯†é’¥
                    print(f"=====================")

            # éªŒè¯è¾“å…¥å‚æ•°
            if not target_path or not os.path.exists(target_path):
                raise ValueError(f"ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target_path}")

            # æ˜¾ç¤ºå½“å‰å¤§æ¨¡å‹é…ç½®ä¿¡æ¯
            self.show_llm_configs()

            # ç¡®è®¤è¢«æµ‹ä»¶
            file_list, detected_languages = self._identify_target_files(target_path, exclude_patterns)
            
            # å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šè¯­è¨€ç±»å‹ï¼Œä½¿ç”¨æ£€æµ‹åˆ°çš„è¯­è¨€ç±»å‹
            if not language_types:
                language_types = detected_languages

            # ç¡®è®¤åˆ†ææ ‡å‡†
            standards_to_use = self._confirm_analysis_standards(language_types, analysis_standard)

            print(f"\nDEBUG: æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç»“æœ: unknown")
            print(f"é…ç½®çš„å¤§æ¨¡å‹æ•°é‡: {len(self.llm_configs)}")
            if self.llm_configs:
                print(f"å·²é…ç½®çš„å¤§æ¨¡å‹: {list(self.llm_configs.keys())}")
            else:
                print("è­¦å‘Š: æ²¡æœ‰é…ç½®ä»»ä½•å¤§æ¨¡å‹")

            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜å‚¨ä¸­é—´ç»“æœ
            with tempfile.TemporaryDirectory() as temp_dir:
                # æ‰§è¡Œä»£ç è´¨é‡åˆ†æ
                analysis_results = await self._perform_analysis(
                    file_list, 
                    standards_to_use, 
                    temp_dir
                )

                # è®¡ç®—æ–°å¢åŠŸèƒ½çš„æ•°æ®
                total_files = len(analysis_results['files_analyzed'])
                total_lines = sum(stat['lines'] for stat in analysis_results['language_stats'].values())
                
                # è®¡ç®—ç ”å‘å†å²æŠ•å…¥ä¼°ç®—å’Œç»´æŠ¤å»ºè®®
                cost_estimate = 0.00
                maintenance_recommendation = None
                if self.use_llm_config == 0:  # åªæœ‰åœ¨å¯ç”¨å¤§æ¨¡å‹æ—¶æ‰è¿›è¡Œè®¡ç®—
                    cost_estimate = await self._estimate_development_cost(total_files, total_lines)
                    maintenance_recommendation = await self._get_maintenance_recommendation(
                        total_files, total_lines, analysis_results["language_stats"], cost_estimate
                    )

                # ç”ŸæˆæŠ¥å‘Š
                report_paths = self._generate_reports(
                    analysis_results, 
                    report_path, 
                    report_format, 
                    target_path,
                    cost_estimate,
                    maintenance_recommendation
                )

            # è¿”å›ç»“æœ
            summary = self._create_summary(analysis_results, file_list, target_path)
             
            return {
                "success": True,
                "report_paths": report_paths,
                "summary": summary,
                "message": "ä»£ç è´¨é‡åˆ†æå®Œæˆ"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "ä»£ç è´¨é‡åˆ†æå¤±è´¥"
            }

    def _identify_target_files(self, target_path: str, exclude_patterns: List[str]) -> Tuple[List[str], List[str]]:
        """
        è¯†åˆ«ç›®æ ‡æ–‡ä»¶å¹¶æ£€æµ‹ç¼–ç¨‹è¯­è¨€ç±»å‹
        """
        file_list = []
        language_extensions = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'cpp',
            '.cs': 'csharp',
            '.go': 'go',
            '.rb': 'ruby',
            '.php': 'php'
        }
        detected_languages = set()

        target_path_obj = Path(target_path)
        
        if target_path_obj.is_file():
            # å•ä¸ªæ–‡ä»¶
            ext = target_path_obj.suffix.lower()
            if ext in language_extensions:
                detected_languages.add(language_extensions[ext])
                file_list.append(str(target_path_obj))
        else:
            # é¡¹ç›®ç›®å½•
            for root, dirs, files in os.walk(target_path):
                # è¿‡æ»¤æ’é™¤çš„ç›®å½•
                dirs[:] = [d for d in dirs if not self._should_exclude(d, exclude_patterns)]
                
                for file in files:
                    if not self._should_exclude(file, exclude_patterns):
                        file_path = os.path.join(root, file)
                        ext = Path(file_path).suffix.lower()
                        
                        if ext in language_extensions:
                            detected_languages.add(language_extensions[ext])
                            file_list.append(file_path)

        return file_list, list(detected_languages)

    def _should_exclude(self, name: str, exclude_patterns: List[str]) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤æŸä¸ªæ–‡ä»¶æˆ–ç›®å½•
        """
        for pattern in exclude_patterns:
            if fnmatch.fnmatch(name, pattern):
                return True
        return False

    def _confirm_analysis_standards(self, language_types: List[str], custom_standards: Dict[str, str]) -> Dict[str, str]:
        """
        ç¡®è®¤åˆ†ææ ‡å‡†
        """
        standards_to_use = {}
        
        for lang in language_types:
            if lang in custom_standards:
                standards_to_use[lang] = custom_standards[lang]
            elif lang in self.default_standards:
                standards_to_use[lang] = self.default_standards[lang]
            else:
                # å¯¹äºæœªçŸ¥è¯­è¨€ï¼Œä½¿ç”¨é€šç”¨æ–‡æœ¬åˆ†æ
                standards_to_use[lang] = "generic"

        return standards_to_use

    async def _perform_analysis(
        self, 
        file_list: List[str], 
        standards: Dict[str, str], 
        temp_dir: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»£ç è´¨é‡åˆ†æ
        """
        analysis_results = {
            "files_analyzed": file_list,
            "issues_found": [],
            "language_stats": defaultdict(lambda: {"lines": 0, "files": 0})
        }

        # è¾“å‡ºå¾…åˆ†ææ–‡ä»¶æ€»æ•°
        total_files = len(file_list)
        print(f"ã€å…±å‘ç° {total_files} ä¸ªå¾…åˆ†æçš„æ–‡ä»¶ã€‘")
        
        # ç»Ÿè®¡å„è¯­è¨€ä»£ç è¡Œæ•°
        for file_path in file_list:
            ext = Path(file_path).suffix.lower()
            lang = self._get_language_from_extension(ext)
            
            if lang:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = len(f.readlines())
                    analysis_results["language_stats"][lang]["lines"] += lines
                    analysis_results["language_stats"][lang]["files"] += 1

        # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹ï¼ˆå®é™…åº”ç”¨ä¸­è¿™é‡Œä¼šè°ƒç”¨å…·ä½“çš„åˆ†æå·¥å…·ï¼‰
        for i, file_path in enumerate(file_list):
            ext = Path(file_path).suffix.lower()
            lang = self._get_language_from_extension(ext)
            
            if lang in standards:
                # è¿™é‡Œæ¨¡æ‹Ÿåˆ†æç»“æœï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„åˆ†æå·¥å…·è°ƒç”¨
                fake_issues = self._generate_fake_issues(file_path, lang, i)
                analysis_results["issues_found"].extend(fake_issues)

            # æ˜¾ç¤ºè¿›åº¦
            percent_complete = (i + 1) / total_files * 100
            print(f"\rã€å·²åˆ†æ {i + 1} ä¸ªæ–‡ä»¶ã€‘ - è¿›åº¦: {percent_complete:.1f}%", end="", flush=True)

        # åœ¨åˆ†æå®Œæˆåæ¢è¡Œï¼Œä»¥ä¾¿åç»­è¾“å‡ºæ›´æ•´æ´
        print("") 

        # ä¸ºæ¯ä¸ªé—®é¢˜è·å–AIå»ºè®®
        if analysis_results["issues_found"]:
            ai_suggestions = await self._get_ai_suggestions(analysis_results["issues_found"])
            
            # å°†AIå»ºè®®æ·»åŠ åˆ°é—®é¢˜ä¸­
            for idx, issue in enumerate(analysis_results["issues_found"]):
                issue["ai_suggestion"] = ai_suggestions[idx] if idx < len(ai_suggestions) else "è·å–AIå»ºè®®å¤±è´¥"

        return analysis_results

    def _get_language_from_extension(self, ext: str) -> str:
        """
        æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–è¯­è¨€ç±»å‹
        """
        ext_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'cpp',
            '.cs': 'csharp',
            '.go': 'go',
            '.rb': 'ruby',
            '.php': 'php'
        }
        return ext_map.get(ext)

    def _generate_fake_issues(self, file_path: str, language: str, index: int) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿçš„é—®é¢˜æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­åº”æ›¿æ¢ä¸ºçœŸå®åˆ†æç»“æœï¼‰
        """
        issues = []
        
        # æ ¹æ®ç´¢å¼•å’Œè¯­è¨€ç±»å‹ç”Ÿæˆä¸€äº›æ¨¡æ‹Ÿé—®é¢˜
        base_issues = [
            {
                "file": file_path,
                "line": 10 + index,
                "severity": "medium",
                "type": "potential_bug",
                "message": f"å¯èƒ½å­˜åœ¨çš„æ½œåœ¨é”™è¯¯ ({language})",
                "solution": "ä»”ç»†æ£€æŸ¥å˜é‡ä½¿ç”¨å’Œè¾¹ç•Œæ¡ä»¶"
            },
            {
                "file": file_path,
                "line": 25 + index,
                "severity": "low",
                "type": "style_issue",
                "message": "ä»£ç é£æ ¼ä¸ç¬¦åˆè§„èŒƒ",
                "solution": "éµå¾ªPEP8æˆ–å…¶ä»–è¯­è¨€ç‰¹å®šçš„ä»£ç è§„èŒƒ"
            }
        ]
        
        # éšæœºæ·»åŠ æ›´å¤šé—®é¢˜
        import random
        if random.random() > 0.5:
            base_issues.append({
                "file": file_path,
                "line": 5 + index * 2,
                "severity": "high",
                "type": "security_vulnerability",
                "message": "å®‰å…¨æ¼æ´ï¼šæœªç»éªŒè¯çš„è¾“å…¥",
                "solution": "å¯¹æ‰€æœ‰ç”¨æˆ·è¾“å…¥è¿›è¡ŒéªŒè¯å’Œæ¸…ç†"
            })
        
        if index % 3 == 0:
            base_issues.append({
                "file": file_path,
                "line": 40 + index,
                "severity": "critical",
                "type": "critical_error",
                "message": "ä¸¥é‡é”™è¯¯ï¼šå¯èƒ½å¯¼è‡´ç¨‹åºå´©æºƒ",
                "solution": "æ£€æŸ¥ç©ºæŒ‡é’ˆå¼•ç”¨å’Œèµ„æºé‡Šæ”¾"
            })
        
        return base_issues

    def _create_summary(self, analysis_results: Dict[str, Any], file_list: List[str], target_path: str) -> Dict[str, Any]:
        """
        åˆ›å»ºåˆ†ææ‘˜è¦ï¼ŒåŒ…å«ç›®æ ‡è·¯å¾„ä¿¡æ¯
        """
        risk_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        
        for issue in analysis_results["issues_found"]:
            severity = issue["severity"]
            if severity in risk_counts:
                risk_counts[severity] += 1

        total_lines = sum(lang_stat["lines"] for lang_stat in analysis_results["language_stats"].values())

        return {
            "target_path": target_path,  # æ·»åŠ ç›®æ ‡è·¯å¾„åˆ°æ‘˜è¦
            "total_files": len(file_list),
            "total_lines": total_lines,
            "language_breakdown": dict(analysis_results["language_stats"]),
            "risk_counts": risk_counts
        }

    def _generate_reports(self, analysis_results: Dict[str, Any], report_path: str, formats: List[str], target_path: str, cost_estimate: float = 0.00, maintenance_recommendation: dict = None) -> List[str]:
        """
        ç”ŸæˆæŠ¥å‘Šï¼Œä¼ é€’ç›®æ ‡è·¯å¾„ä¿¡æ¯å’Œæ–°å¢åŠŸèƒ½æ•°æ®
        """
        os.makedirs(report_path, exist_ok=True)
        
        report_paths = []
        timestamp = str(int(asyncio.get_event_loop().time()))
        
        for fmt in formats:
            if fmt == "html":
                path = os.path.join(report_path, f"analysis_report_{timestamp}.html")
                self._generate_html_report(analysis_results, path, target_path, cost_estimate, maintenance_recommendation)
                report_paths.append(path)
            elif fmt == "pdf":
                path = os.path.join(report_path, f"analysis_report_{timestamp}.pdf")
                self._generate_pdf_report(analysis_results, path, target_path, cost_estimate, maintenance_recommendation)
                report_paths.append(path)
            elif fmt == "txt":
                path = os.path.join(report_path, f"analysis_report_{timestamp}.txt")
                self._generate_text_report(analysis_results, path, target_path, cost_estimate, maintenance_recommendation)
                report_paths.append(path)
        
        return report_paths

    def _generate_html_report(self, analysis_results: Dict[str, Any], output_path: str, target_path: str, cost_estimate: float = 0.00, maintenance_recommendation: dict = None):
        """
        ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Šï¼ŒåŒ…å«ç›®æ ‡è·¯å¾„ä¿¡æ¯å’Œæ–°å¢åŠŸèƒ½
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('<!DOCTYPE html>\n<html>\n<head>\n')
            f.write('<meta charset="UTF-8">\n')
            f.write('<title>é¾™æâ€”â€”ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š</title>\n')
            f.write('<style>\n')
            f.write('body { font-family: "Microsoft YaHei", Arial, sans-serif; margin: 0; padding: 20px; background-color: #f5f5f5; }\n')
            f.write('.header { background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 20px; text-align: center; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }\n')
            f.write('.logo { float: left; margin-top: -10px; }\n')
            f.write('.container { max-width: 1200px; margin: 20px auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 0 20px rgba(0,0,0,0.1); }\n')
            f.write('h1 { margin: 0; font-size: 2em; }\n')
            f.write('h2 { color: #333; border-bottom: 2px solid #667eea; padding-bottom: 5px; }\n')
            f.write('table { border-collapse: collapse; width: 100%; margin: 20px 0; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }\n')
            f.write('th, td { border: 1px solid #ddd; padding: 12px; text-align: left; vertical-align: top; }\n')
            f.write('th { background-color: #f2f2f2; cursor: pointer; font-weight: bold; }\n')
            f.write('th:hover { background-color: #e0e0e0; }\n')
            f.write('.critical { background-color: #ffece8; }\n')
            f.write('.high { background-color: #fef5e7; }\n')
            f.write('.medium { background-color: #fff8e1; }\n')
            f.write('.low { background-color: #f5f5f5; }\n')
            f.write('.filter-container { margin: 20px 0; }\n')
            f.write('.filter-input { margin-right: 10px; padding: 10px; width: 300px; border: 1px solid #ddd; border-radius: 4px; }\n')
            f.write('#searchInput { width: 100%; }\n')
            f.write('.summary-box { background: #f9f9f9; padding: 15px; border-radius: 5px; margin: 15px 0; border-left: 4px solid #667eea; }\n')
            f.write('.summary-item { margin: 5px 0; }\n')
            f.write('.section { margin: 25px 0; }\n')
            f.write('.highlight { background-color: #ffffcc; padding: 2px 4px; border-radius: 3px; }\n')
            f.write('</style>\n')
            f.write('</head>\n<body>\n')
            f.write('<div class="header">\n')
            f.write('<img src="../cdico_64_64.jpg" alt="é¾™æ Logo" class="logo" width="64" height="64">\n')
            f.write('<h1>é¾™æâ€”â€”ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š</h1>\n')
            f.write('</div>\n')
            f.write('<div class="container">\n')

            # å†™å…¥æ‘˜è¦ä¿¡æ¯ï¼ŒåŒ…å«ç›®æ ‡è·¯å¾„
            f.write('<div class="section"><h2>ğŸ“Š åˆ†ææ‘˜è¦</h2>\n')
            f.write('<div class="summary-box">\n')
            f.write('<div class="summary-item">ğŸ“ <strong>åˆ†æç›®æ ‡:</strong> {}</div>\n'.format(target_path))
            f.write('<div class="summary-item">ğŸ“„ <strong>åˆ†ææ–‡ä»¶æ•°:</strong> {}</div>\n'.format(len(analysis_results["files_analyzed"])))
            f.write('<div class="summary-item">ğŸ“ <strong>æ€»ä»£ç è¡Œæ•°:</strong> {}</div>\n'.format(sum(stat["lines"] for stat in analysis_results["language_stats"].values())))
            
            # é£é™©ç»Ÿè®¡
            risk_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
            for issue in analysis_results["issues_found"]:
                risk_counts[issue["severity"]] += 1
            
            f.write('<div class="summary-item">ğŸ‰ <strong>è‡´å‘½é£é™©:</strong> <span class="highlight">{}</span></div>\n'.format(risk_counts["critical"]))
            f.write('<div class="summary-item">âš ï¸ <strong>é«˜çº§é£é™©:</strong> <span class="highlight">{}</span></div>\n'.format(risk_counts["high"]))
            f.write('<div class="summary-item">âš¡ <strong>ä¸­çº§é£é™©:</strong> <span class="highlight">{}</span></div>\n'.format(risk_counts["medium"]))
            f.write('<div class="summary-item">â„¹ï¸ <strong>æ™®é€šé£é™©:</strong> <span class="highlight">{}</span></div>\n'.format(risk_counts["low"]))
            f.write('</div></div>\n')

            # æ·»åŠ ç ”å‘å†å²æŠ•å…¥ä¼°ç®—ï¼ˆå¦‚æœå¯ç”¨å¤§æ¨¡å‹ï¼‰
            if self.use_llm_config == 0 and cost_estimate > 0:
                f.write('<div class="section"><h2>ğŸ’° ç ”å‘å†å²æŠ•å…¥ä¼°ç®—</h2>\n')
                f.write('<div class="summary-box">\n')
                f.write('<div class="summary-item">ã€ç ”å‘å†å²æŠ•å…¥ä¼°ç®—ï¼ˆä¸ä½¿ç”¨ä»»ä½•aiå·¥å…·ã€é‡‡ç”¨è¾ƒä¸ºä¼ ç»Ÿçš„çº¯æ‰‹å·¥å¼€å‘ï¼‰ï¼šæˆæœ¬ï¼ˆäºº/æ—¥ï¼‰ã€‘ï¼š{}</div>\n'.format(cost_estimate))
                f.write('</div></div>\n')
            
            # æ·»åŠ ç»§ç»­ç»´æŠ¤å»ºè®®ï¼ˆå¦‚æœå¯ç”¨å¤§æ¨¡å‹ï¼‰
            if self.use_llm_config == 0 and maintenance_recommendation:
                f.write('<div class="section"><h2>ğŸ’¡ ç»§ç»­ç»´æŠ¤å»ºè®®</h2>\n')
                f.write('<div class="summary-box">\n')
                f.write('<div class="summary-item">ã€æ­¤é¡¹ç›®æ˜¯å¦å€¼å¾—ç»§ç»­ç»´æŠ¤ã€‘ï¼š<strong>{}</strong></div>\n'.format(maintenance_recommendation["worth_maintaining"]))
                f.write('<div class="summary-item">ã€åŸç”Ÿè¯´æ˜ã€‘ï¼š{}</div>\n'.format(maintenance_recommendation["reasoning"]))
                f.write('</div></div>\n')

            # è¯­è¨€åˆ†å¸ƒ
            f.write('<div class="section"><h2>ğŸŒ è¯­è¨€åˆ†å¸ƒ</h2>\n')
            f.write('<table>\n')
            f.write('<tr><th>è¯­è¨€</th><th>æ–‡ä»¶æ•°</th><th>ä»£ç è¡Œæ•°</th><th>å æ¯”</th></tr>\n')
            
            total_lines = sum(stat["lines"] for stat in analysis_results["language_stats"].values())
            for lang, stats in analysis_results["language_stats"].items():
                percentage = (stats["lines"] / total_lines * 100) if total_lines > 0 else 0
                f.write('<tr><td>{}</td><td>{}</td><td>{}</td><td>{:.2f}%</td></tr>\n'.format(lang, stats["files"], stats["lines"], percentage))
            
            f.write('</table></div>\n')

            # é—®é¢˜è¯¦æƒ…è¡¨æ ¼
            f.write('<div class="section"><h2>ğŸ” é—®é¢˜è¯¦æƒ…</h2>\n')
            f.write('<div class="filter-container">\n')
            f.write('<input type="text" id="searchInput" placeholder="ğŸ” è¾“å…¥å…³é”®å­—è¿‡æ»¤é—®é¢˜..." class="filter-input">\n')
            f.write('</div>\n')
            f.write('<table id="issuesTable">\n')
            f.write('<thead>\n')
            f.write('<tr>\n')
            f.write('<th onclick="sortTable(0)">æ–‡ä»¶ ğŸ“„</th>\n<th onclick="sortTable(1)">è¡Œå· #ï¸âƒ£</th>\n<th onclick="sortTable(2)">ä¸¥é‡ç¨‹åº¦ âš ï¸</th>\n<th onclick="sortTable(3)">ç±»å‹ ğŸ·ï¸</th>\n<th onclick="sortTable(4)">é—®é¢˜æè¿° ğŸ“</th>\n<th onclick="sortTable(5)">è§£å†³æ–¹æ¡ˆ ğŸ’¡</th>\n<th onclick="sortTable(6)">AIå»ºè®® ğŸ¤–</th>\n')
            f.write('</tr>\n')
            f.write('</thead>\n')
            f.write('<tbody>\n')
            
            for issue in analysis_results["issues_found"]:
                severity_class = issue["severity"]
                severity_label = self.risk_levels[issue["severity"]]["label"]
                ai_suggestion = issue.get("ai_suggestion", "æœªè·å–åˆ°AIå»ºè®®")
                f.write('<tr class="{}">\n'.format(severity_class))
                f.write('<td>{}</td>\n<td>{}</td>\n<td>{}</td>\n<td>{}</td>\n<td>{}</td>\n<td>{}</td>\n<td>{}</td>\n'.format(
                    issue["file"], issue["line"], severity_label, issue["type"], 
                    issue["message"], issue["solution"], ai_suggestion))
                f.write('</tr>\n')
            
            f.write('</tbody>\n')
            f.write('</table></div>\n')

            # æ·»åŠ JavaScriptåŠŸèƒ½
            f.write('<script>\n')
            f.write('''
function sortTable(columnIndex) {
    const table = document.getElementById("issuesTable");
    const tbody = table.querySelector('tbody');
    const rows = Array.from(tbody.querySelectorAll('tr'));
    
    rows.sort((a, b) => {
        const aVal = a.cells[columnIndex].innerText.trim();
        const bVal = b.cells[columnIndex].innerText.trim();
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—
        if (!isNaN(aVal) && !isNaN(bVal)) {
            return parseFloat(aVal) - parseFloat(bVal);
        } else {
            return aVal.localeCompare(bVal);
        }
    });
    
    rows.forEach(row => tbody.appendChild(row));
}

document.getElementById('searchInput').addEventListener('keyup', function() {
    const searchTerm = this.value.toLowerCase();
    const rows = document.querySelectorAll('#issuesTable tbody tr');
    
    rows.forEach(row => {
        const text = row.textContent.toLowerCase();
        if (text.includes(searchTerm)) {
            row.style.display = '';
        } else {
            row.style.display = 'none';
        }
    });
});
</script>
''')
            f.write('</div>\n</body>\n</html>')

    def _generate_pdf_report(self, analysis_results: Dict[str, Any], output_path: str, target_path: str, cost_estimate: float = 0.00, maintenance_recommendation: dict = None):
        """
        ç”ŸæˆPDFæ ¼å¼çš„æŠ¥å‘Šï¼ŒåŒ…å«ç›®æ ‡è·¯å¾„ä¿¡æ¯å’Œæ–°å¢åŠŸèƒ½
        """
        from reportlab.lib.pagesizes import letter, A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.lib import colors
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        import platform

        # é¦–å…ˆå°è¯•æ³¨å†Œä¸­æ–‡å­—ä½“
        system = platform.system()
        font_path = ""
        font_name = "CustomChineseFont"
        
        # å¢åŠ æ›´å¤šå­—ä½“é€‰é¡¹ä»¥æé«˜å…¼å®¹æ€§
        if system == "Windows":
            # å°è¯•å¤šä¸ªå¸¸è§çš„ä¸­æ–‡å­—ä½“è·¯å¾„
            possible_paths = [
                "C:/Windows/Fonts/simsun.ttc",      # å®‹ä½“
                "C:/Windows/Fonts/simhei.ttf",      # é»‘ä½“
                "C:/Windows/Fonts/msyh.ttc",        # å¾®è½¯é›…é»‘
                "C:/Windows/Fonts/msyhbd.ttc",      # å¾®è½¯é›…é»‘ç²—ä½“
                "C:/Windows/Fonts/simsunb.ttf",     # å®‹ä½“ç²—ä½“
                "C:/Windows/Fonts/Arial Unicode.ttf",  # Arial Unicode
                "C:/Windows/Fonts/mingliu.ttc",     # ç»†æ˜ä½“
                "C:/Windows/Fonts/msjh.ttc"         # å¾®è½¯æ­£é»‘ä½“
            ]
        elif system == "Darwin":  # macOS
            possible_paths = [
                "/System/Library/Fonts/STHeiti Light.ttc",  # é»‘ä½“-ç®€
                "/System/Library/Fonts/STHeiti Medium.ttc", # é»‘ä½“-ç®€
                "/System/Library/Fonts/STSong.ttc",         # å®‹ä½“-ç®€
                "/System/Library/Fonts/PingFang.ttc",       # è‹¹æœ
                "/System/Library/Fonts/Helvetica.ttc",      # Helvetica
                "/System/Library/Fonts/Menlo.ttc",          # Menlo
                "/Library/Fonts/Songti.ttc",                # å®‹ä½“
                "/Library/Fonts/Heiti.ttc"                  # é»‘ä½“
            ]
        else:  # Linux
            possible_paths = [
                "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",   # æ–‡æ³‰é©¿å¾®ç±³é»‘
                "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc",     # æ–‡æ³‰é©¿æ­£é»‘
                "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc", # Noto Sans CJK
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",  # DejaVu Sans
                "/usr/share/fonts/TTF/SourceHanSansCN-Regular.otf", # æ€æºé»‘ä½“
                "/usr/share/fonts/google-noto-cjk/SourceHanSansCN-Regular.ttc", # Google Noto CJK
                "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf", # Liberation Sans
                "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc" # Noto Sans CJK
            ]
        
        # å°è¯•æ‰¾åˆ°å¯ç”¨çš„å­—ä½“æ–‡ä»¶
        for path in possible_paths:
            if os.path.exists(path):
                font_path = path
                break

        # æ³¨å†Œä¸­æ–‡å­—ä½“
        if font_path and os.path.exists(font_path):
            try:
                # å…ˆå°è¯•æ³¨å†Œå­—ä½“
                pdfmetrics.registerFont(TTFont(font_name, font_path))
                
                # éªŒè¯å­—ä½“æ˜¯å¦æ³¨å†ŒæˆåŠŸ
                registered_fonts = pdfmetrics.getRegisteredFontNames()
                if font_name in registered_fonts:
                    print(f"æˆåŠŸæ³¨å†Œå­—ä½“: {font_path}")
                else:
                    print(f"å­—ä½“æ³¨å†Œå¤±è´¥: {font_path}")
                    font_name = "Helvetica"  # å›é€€åˆ°é»˜è®¤å­—ä½“
            except Exception as e:
                print(f"å­—ä½“æ³¨å†Œå¼‚å¸¸: {e}")
                font_name = "Helvetica"  # å›é€€åˆ°é»˜è®¤å­—ä½“
        else:
            print(f"æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
            # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
            font_name = "Helvetica"

        doc = SimpleDocTemplate(output_path, pagesize=A4)
        styles = getSampleStyleSheet()
        
        # è‡ªå®šä¹‰æ ·å¼ä½¿ç”¨ä¸­æ–‡å­—ä½“
        chinese_style = ParagraphStyle(
            'ChineseStyle',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=10,
            leading=14
        )
        
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=20,
            spaceAfter=30,
            alignment=1,  # å±…ä¸­å¯¹é½
            textColor=colors.HexColor('#667eea')
        )
        
        heading2_style = ParagraphStyle(
            'CustomHeading2',
            parent=styles['Heading2'],
            fontName=font_name,
            fontSize=14,
            spaceAfter=12,
            textColor=colors.HexColor('#764ba2'),
            borderWidth=2,
            borderColor=colors.HexColor('#667eea'),
            borderPadding=5,
            backColor=colors.lightgrey
        )
        
        story = []

        # æ ‡é¢˜å’ŒLogo
        # å°è¯•å¤šä¸ªå¯èƒ½çš„å›¾ç‰‡è·¯å¾„
        logo_paths = [
            os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "cdico_64_64.jpg"),  # é¡¹ç›®æ ¹ç›®å½•
            os.path.join(os.path.dirname(os.path.abspath(__file__)), "cdico_64_64.jpg"),      # å½“å‰ç›®å½•
            os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "cdico_64_64.jpg"),  # é¡¹ç›®æ ¹ç›®å½•
            "cdico_64_64.jpg"  # å½“å‰å·¥ä½œç›®å½•
        ]
        
        logo_path = None
        for path in logo_paths:
            if os.path.exists(path):
                logo_path = path
                break
        
        if logo_path:
            # åˆ›å»ºä¸€ä¸ªåŒ…å«å±…ä¸­å›¾ç‰‡çš„è¡¨æ ¼
            logo_img = Image(logo_path, width=64, height=64)
            
            # åˆ›å»ºä¸€ä¸ªä¸‰åˆ—çš„è¡¨æ ¼ï¼Œå›¾ç‰‡æ”¾åœ¨ä¸­é—´åˆ—ï¼Œå®ç°å±…ä¸­
            logo_data = [['', logo_img, '']]
            # è®¡ç®—å·¦å³ä¸¤ä¾§çš„å®½åº¦ï¼Œä½¿å›¾ç‰‡å±…ä¸­
            side_padding = (A4[0] - 64) / 2
            logo_table = Table(logo_data, colWidths=[side_padding * 0.5, 64, side_padding * 0.5], style=[
                ('ALIGN', (1, 0), (1, 0), 'CENTER'),  # å›¾ç‰‡åˆ—å±…ä¸­å¯¹é½
                ('VALIGN', (1, 0), (1, 0), 'TOP'),   # å›¾ç‰‡é¡¶éƒ¨å¯¹é½
                ('BOX', (0, 0), (-1, -1), 0, colors.white),  # éšè—å¤–è¾¹æ¡†
                ('TOPPADDING', (0, 0), (-1, -1), 20),  # ä¸Šè¾¹è·
                ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # ä¸‹è¾¹è·
            ])
            
            story.append(logo_table)
        else:
            # å¦‚æœå›¾ç‰‡ä¸å­˜åœ¨ï¼Œæ·»åŠ ä¸€ç‚¹ç©ºç™½åŒºåŸŸä½œä¸ºå ä½
            story.append(Spacer(1, 84))  # 64çš„é«˜åº¦åŠ ä¸Šä¸€äº›é—´è·
        
        # æ·»åŠ æ ‡é¢˜
        title = Paragraph("é¾™æâ€”â€”ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š", title_style)
        story.append(title)
        story.append(Spacer(1, 12))

        # æ‘˜è¦éƒ¨åˆ†
        summary_data = [
            ["<b>åˆ†æç›®æ ‡:</b>", Paragraph(target_path, chinese_style)],
            ["<b>åˆ†ææ–‡ä»¶æ•°:</b>", str(len(analysis_results["files_analyzed"]))],
            ["<b>æ€»ä»£ç è¡Œæ•°:</b>", str(sum(stat["lines"] for stat in analysis_results["language_stats"].values()))]
        ]

        # é£é™©ç»Ÿè®¡
        risk_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        for issue in analysis_results["issues_found"]:
            risk_counts[issue["severity"]] += 1

        summary_data.extend([
            ["è‡´å‘½é£é™©:", str(risk_counts["critical"])],
            ["é«˜çº§é£é™©:", str(risk_counts["high"])],
            ["ä¸­çº§é£é™©:", str(risk_counts["medium"])],
            ["æ™®é€šé£é™©:", str(risk_counts["low"])]
        ])
        
        # æ·»åŠ æ‘˜è¦è¡¨æ ¼
        summary_table = Table(summary_data, colWidths=[2*inch, 4*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#f2f2f2')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.lightblue),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 10),
            ('TOPPADDING', (0, 0), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(summary_table)
        story.append(Spacer(1, 12))

        # æ·»åŠ ç ”å‘å†å²æŠ•å…¥ä¼°ç®—ï¼ˆå¦‚æœå¯ç”¨å¤§æ¨¡å‹ï¼‰
        if self.use_llm_config == 0 and cost_estimate > 0:
            story.append(Paragraph(f"ã€ç ”å‘å†å²æŠ•å…¥ä¼°ç®—ï¼ˆä¸ä½¿ç”¨ä»»ä½•aiå·¥å…·ã€é‡‡ç”¨è¾ƒä¸ºä¼ ç»Ÿçš„çº¯æ‰‹å·¥å¼€å‘ï¼‰ï¼šæˆæœ¬ï¼ˆäºº/æ—¥ï¼‰ã€‘ï¼š{cost_estimate}", heading2_style))
            story.append(Paragraph("ï¼ˆä¸ä½¿ç”¨ä»»ä½•aiå·¥å…·ã€é‡‡ç”¨è¾ƒä¸ºä¼ ç»Ÿçš„çº¯æ‰‹å·¥å¼€å‘ï¼Œä¼°ç®—å¯èƒ½å­˜åœ¨åå·®ï¼Œè¯·è°¨æ…å‚è€ƒï¼‰", chinese_style))
            story.append(Spacer(1, 12))

        # æ·»åŠ ç»§ç»­ç»´æŠ¤å»ºè®®ï¼ˆå¦‚æœå¯ç”¨å¤§æ¨¡å‹ï¼‰
        if self.use_llm_config == 0 and maintenance_recommendation:
            story.append(Paragraph("ã€ç»§ç»­ç»´æŠ¤å»ºè®®ã€‘", heading2_style))
            story.append(Paragraph(f"ã€æ­¤é¡¹ç›®æ˜¯å¦å€¼å¾—ç»§ç»­ç»´æŠ¤ã€‘ï¼š{maintenance_recommendation['worth_maintaining']}", chinese_style))
            story.append(Paragraph(f"ã€åŸå› è¯´æ˜ã€‘ï¼š{maintenance_recommendation['reasoning']}", chinese_style))
            story.append(Spacer(1, 12))

        # è¯­è¨€åˆ†å¸ƒæ ‡é¢˜
        lang_title = Paragraph("è¯­è¨€åˆ†å¸ƒ", heading2_style)
        story.append(lang_title)

        total_lines = sum(stat["lines"] for stat in analysis_results["language_stats"].values())
        lang_data = [[Paragraph("<b>è¯­è¨€</b>", chinese_style), Paragraph("<b>æ–‡ä»¶æ•°</b>", chinese_style), 
                     Paragraph("<b>ä»£ç è¡Œæ•°</b>", chinese_style), Paragraph("<b>å æ¯”</b>", chinese_style)]]
        for lang, stats in analysis_results["language_stats"].items():
            percentage = (stats["lines"] / total_lines * 100) if total_lines > 0 else 0
            lang_data.append([
                Paragraph(lang, chinese_style), 
                str(stats["files"]), 
                str(stats["lines"]), 
                f"{percentage:.2f}%"
            ])

        lang_table = Table(lang_data, colWidths=[1.5*inch, 1*inch, 1.5*inch, 1*inch])
        lang_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 8),
            ('TOPPADDING', (0, 0), (-1, -1), 6),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(lang_table)
        story.append(Spacer(1, 12))

        # é—®é¢˜è¯¦æƒ…æ ‡é¢˜
        issues_title = Paragraph("é—®é¢˜è¯¦æƒ…", heading2_style)
        story.append(issues_title)

        # é—®é¢˜è¯¦æƒ…è¡¨æ ¼ - ç°åœ¨åŒ…å«AIå»ºè®®åˆ—
        headers = [
            Paragraph("<b>æ–‡ä»¶</b>", chinese_style), 
            Paragraph("<b>è¡Œå·</b>", chinese_style), 
            Paragraph("<b>ä¸¥é‡ç¨‹åº¦</b>", chinese_style), 
            Paragraph("<b>ç±»å‹</b>", chinese_style), 
            Paragraph("<b>é—®é¢˜æè¿°</b>", chinese_style), 
            Paragraph("<b>è§£å†³æ–¹æ¡ˆ</b>", chinese_style),
            Paragraph("<b>AIå»ºè®®</b>", chinese_style)
        ]
        issues_data = [headers]
        
        for issue in analysis_results["issues_found"]:
            severity_label = self.risk_levels[issue["severity"]]["label"]
            # æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬ä»¥é€‚åº”PDFè¡¨æ ¼
            file_path = issue["file"][-30:] if len(issue["file"]) > 30 else issue["file"]
            message = issue["message"][:40] + "..." if len(issue["message"]) > 40 else issue["message"]
            solution = issue["solution"][:40] + "..." if len(issue["solution"]) > 40 else issue["solution"]
            ai_suggestion = issue.get("ai_suggestion", "æœªè·å–åˆ°AIå»ºè®®")
            ai_suggestion_short = ai_suggestion[:40] + "..." if len(ai_suggestion) > 40 else ai_suggestion
            
            issues_data.append([
                Paragraph(file_path, chinese_style),
                str(issue["line"]),
                Paragraph(severity_label, chinese_style),
                Paragraph(issue["type"], chinese_style),
                Paragraph(message, chinese_style),
                Paragraph(solution, chinese_style),
                Paragraph(ai_suggestion_short, chinese_style)
            ])

        # åˆ›å»ºè¡¨æ ¼å¹¶è®¾ç½®æ ·å¼ï¼ˆå¢åŠ ä¸€åˆ—ï¼Œè°ƒæ•´åˆ—å®½ï¼‰
        issues_table = Table(issues_data, colWidths=[1.2*inch, 0.5*inch, 0.7*inch, 0.7*inch, 1.2*inch, 1.2*inch, 1.2*inch])
        issues_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 8),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 6),
            ('TOPPADDING', (0, 0), (-1, -1), 4),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 4),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            # æ ¹æ®ä¸¥é‡ç¨‹åº¦è®¾ç½®èƒŒæ™¯è‰²
            *[('BACKGROUND', (0, i+1), (-1, i+1), 
               colors.HexColor('#ffece8') if analysis_results["issues_found"][i]["severity"] == "critical" else
               colors.HexColor('#fef5e7') if analysis_results["issues_found"][i]["severity"] == "high" else
               colors.HexColor('#fff8e1') if analysis_results["issues_found"][i]["severity"] == "medium" else
               colors.HexColor('#f5f5f5'))
              for i in range(min(len(analysis_results["issues_found"]), 100))]  # é™åˆ¶é¢œè‰²è®¾ç½®æ•°é‡ä»¥æé«˜æ€§èƒ½
        ]))

        story.append(issues_table)

        # æ„å»ºPDF
        doc.build(story)

    def _generate_text_report(self, analysis_results: Dict[str, Any], output_path: str, target_path: str, cost_estimate: float = 0.00, maintenance_recommendation: dict = None):
        """
        ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„æŠ¥å‘Šï¼ŒåŒ…å«ç›®æ ‡è·¯å¾„ä¿¡æ¯å’Œæ–°å¢åŠŸèƒ½
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("==========================================\n")
            f.write("         é¾™æâ€”â€”ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š\n")
            f.write("==========================================\n")
            f.write(f"åˆ†æç›®æ ‡: {target_path}\n")
            f.write(f"åˆ†ææ—¶é—´: {asyncio.get_event_loop().time()}\n")
            f.write(f"åˆ†ææ–‡ä»¶æ•°: {len(analysis_results['files_analyzed'])}\n")
            f.write(f"æ€»ä»£ç è¡Œæ•°: {sum(stat['lines'] for stat in analysis_results['language_stats'].values())}\n\n")
            
            # é£é™©ç»Ÿè®¡
            risk_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
            for issue in analysis_results["issues_found"]:
                risk_counts[issue["severity"]] += 1
            
            f.write("é£é™©ç»Ÿè®¡:\n")
            f.write(f"- è‡´å‘½é£é™©: {risk_counts['critical']}\n")
            f.write(f"- é«˜çº§é£é™©: {risk_counts['high']}\n")
            f.write(f"- ä¸­çº§é£é™©: {risk_counts['medium']}\n")
            f.write(f"- æ™®é€šé£é™©: {risk_counts['low']}\n\n")
            
            f.write("è¯­è¨€åˆ†å¸ƒ:\n")
            total_lines = sum(stat["lines"] for stat in analysis_results["language_stats"].values())
            for lang, stats in analysis_results["language_stats"].items():
                percentage = (stats["lines"] / total_lines * 100) if total_lines > 0 else 0
                f.write(f"- {lang}: {stats['files']} æ–‡ä»¶, {stats['lines']} è¡Œ ({percentage:.2f}%)\n")
            
            # æ·»åŠ ç ”å‘å†å²æŠ•å…¥ä¼°ç®—ï¼ˆå¦‚æœå¯ç”¨å¤§æ¨¡å‹ï¼‰
            if self.use_llm_config == 0 and cost_estimate > 0:
                f.write(f"\nã€ç ”å‘å†å²æŠ•å…¥ä¼°ç®—ï¼ˆä¸ä½¿ç”¨ä»»ä½•aiå·¥å…·ã€é‡‡ç”¨è¾ƒä¸ºä¼ ç»Ÿçš„çº¯æ‰‹å·¥å¼€å‘ï¼‰ï¼šæˆæœ¬ï¼ˆäºº/æ—¥ï¼‰ã€‘ï¼š{cost_estimate}\n")
            
            # æ·»åŠ ç»§ç»­ç»´æŠ¤å»ºè®®ï¼ˆå¦‚æœå¯ç”¨å¤§æ¨¡å‹ï¼‰
            if self.use_llm_config == 0 and maintenance_recommendation:
                f.write(f"\nã€ç»§ç»­ç»´æŠ¤å»ºè®®ã€‘\n")
                f.write(f"ã€æ­¤é¡¹ç›®æ˜¯å¦å€¼å¾—ç»§ç»­ç»´æŠ¤ã€‘ï¼š{maintenance_recommendation['worth_maintaining']}\n")
                f.write(f"ã€åŸç”Ÿè¯´æ˜ã€‘ï¼š{maintenance_recommendation['reasoning']}\n")
            
            f.write("\né—®é¢˜è¯¦æƒ…:\n")
            f.write("=" * 80 + "\n")
            for i, issue in enumerate(analysis_results["issues_found"], 1):
                severity_label = self.risk_levels[issue["severity"]]["label"]
                ai_suggestion = issue.get("ai_suggestion", "æœªè·å–åˆ°AIå»ºè®®")
                f.write(f"{i}. æ–‡ä»¶: {issue['file']} (ç¬¬{issue['line']}è¡Œ)\n")
                f.write(f"   ä¸¥é‡ç¨‹åº¦: {severity_label}\n")
                f.write(f"   ç±»å‹: {issue['type']}\n")
                f.write(f"   é—®é¢˜: {issue['message']}\n")
                f.write(f"   è§£å†³æ–¹æ¡ˆ: {issue['solution']}\n")
                f.write(f"   AIå»ºè®®: {ai_suggestion}\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("æŠ¥å‘Šç”Ÿæˆå®Œæ¯•\n")

    def validate_input(self, inputs: Dict[str, Any]) -> bool:
        """
        éªŒè¯è¾“å…¥å‚æ•°çš„æœ‰æ•ˆæ€§
        """
        required_fields = ["target_path"]
        for field in required_fields:
            if field not in inputs or not inputs[field]:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {field}")
        
        if not os.path.exists(inputs["target_path"]):
            raise ValueError(f"ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {inputs['target_path']}")
        
        return True

    def run_skill(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŒæ­¥æ‰§è¡ŒæŠ€èƒ½çš„æ–¹æ³•
        """
        return asyncio.run(self.execute(inputs))